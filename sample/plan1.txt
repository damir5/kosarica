Functional Specification and Strategic Implementation Master Plan for Croatian Retail Price Aggregation Ecosystem1. Executive Summary and Strategic ContextThe Croatian grocery retail market is currently undergoing a significant digital transformation, characterized by a fragmented landscape of legacy brick-and-mortar operations, rapidly expanding proximity networks, and sophisticated e-commerce platforms. For the development of a robust, market-leading price comparison application, this environment presents both a substantial engineering challenge and a lucrative opportunity for data aggregation.The primary objective of this functional specification is to define the architecture for a centralized pricing intelligence engine capable of ingesting, normalizing, and serving high-fidelity pricing data from the entire spectrum of Croatian retailers. This includes market leaders like Konzum Plus, challengers such as Spar and Plodine, discounters like Lidl and Eurospin, and the expansive network of Studenac proximity stores.The proposed system goes beyond simple web scraping. It envisions a hybrid data ingestion pipeline that combines:Official API Integration: Leveraging developer portals where available (e.g., Tommy).Mobile API Reverse Engineering: Intercepting traffic from loyalty apps (Lidl Plus, Moj Studenac) to capture personalized and loyalty-tier pricing.Delivery Platform Proxying: utilizing Wolt and Glovo interfaces as real-time inventory checks for retailers lacking their own digital storefronts.Geospatial Grid Crawling: Systematically mapping the physical coordinates of every retail outlet to enable location-based pricing logic.This document serves as the primary artifact for the engineering team. It provides a granular analysis of each retailer's digital footprint, constructing a "Data Accessibility Profile" that dictates the technical approach—whether it involves parsing HTML, negotiating OAuth tokens, or OCR-scanning digital leaflets. Furthermore, it incorporates an analysis of existing open-source intelligence, specifically the cijene-api repository 1, using it as a foundational seed list for store discovery while outlining the necessary architectural upgrades to meet enterprise-grade requirements for real-time data accuracy and geospatial precision.The output of this system will be a queryable, normalized database linking Product IDs (GTIN/EAN) across disparate retailers, enabling the end-user to answer the fundamental question: "Where is this basket of goods cheapest, right now, near me?"2. Analysis of Existing Open-Source Intelligence (The "Senko" Baseline)The user query highlights the existence of the cijene-api repository hosted on GitHub.1 Before architecting a new solution, it is imperative to analyze this existing artifact to understand its utility as a "Seed List" and identify its architectural limitations which our new functional spec must overcome.2.1 Asset ReviewThe repository structure indicates a Python-based ecosystem utilizing Playwright for scraping and BeautifulSoup for parsing.1 Key components identified include:crawler/: Contains the logic for fetching data.enrichment/: Suggests post-processing of data, likely for adding metadata.service/: Implies a backend component, potentially for serving the data.csv/: The output format appears to be flat files (CSV), which limits real-time query capabilities.2.2 Strategic Utility: The "Seed List"The most immediate value of the cijene-api is not its code, but its configuration. It serves as a verified directory of:Valid Store URLs: The repository likely contains a list of entry points (start URLs) for the crawlers.Selector Logic: It provides a historical record of CSS selectors used to extract prices, which accelerates our development cycle by providing a "known good" starting point for HTML parsing.Store Identifiers: The enrichment folder likely contains mappings of store names to IDs, which can be ingested immediately to populate our StoreRegistry database.2.3 Architectural Gap AnalysisTo meet the requirements of a modern price comparison app, we must transcend the limitations of the cijene-api model:Featurecijene-api (Inferred)Proposed Enterprise SpecData SourcePrimarily Web Scraping (HTML)Hybrid: API + Mobile App Traffic + HTMLLocation LogicStatic / General National PriceZone-based / Store-specific PricingRefresh RateBatch / Daily (CSV output)Real-time / Hourly (Stream Processing)InventoryAssumed AvailableValidated via Delivery Proxy (Wolt/Glovo)NormalizationBasic String MatchingGTIN + NLP + Fuzzy Logic EngineConclusion: We will utilize cijene-api solely as a Discovery Layer. We will parse its configuration files to extract the initial list of target domains and store locations, but the ingestion logic will be rebuilt from scratch to support the complex, app-based authentication required for retailers like Lidl and Studenac.3. System Architecture & Functional SpecificationsThe platform is designed as a distributed system comprised of four distinct layers: Discovery, Ingestion, Normalization, and Presentation.3.1 The Discovery Layer (Geospatial Crawler)This layer is responsible for maintaining the "Ground Truth" of the Croatian retail network. Prices are meaningless without location context.Function: Iterate through a geospatial grid covering Croatia.Action: Query the "Store Locator" endpoints of every retailer.Output: A StoreRegistry database containing:provider_id (e.g., "konzum")store_remote_id (e.g., "1205")geo_location (Lat/Lon)format (Super/Hyper/Mini)3.2 The Ingestion Layer (The "Runners")This is the core execution layer. It consists of modular "Runners," each tailored to the specific Data Accessibility Profile (DAP) of a retailer.Type A Runner (API Client): For retailers with documented or discoverable REST APIs (Tommy, Konzum App).Type B Runner (Web Scraper): For traditional e-commerce sites (Konzum Web, DM, Spar). Uses headless browsers.Type C Runner (Mobile Impersonator): For app-only discounters (Lidl, Studenac). These scripts spoof mobile device headers to access internal JSON feeds.Type D Runner (Delivery Proxy): Scrapes Wolt/Glovo to infer inventory for stores without their own digital catalog.3.3 The Normalization Layer (The "Rosetta Stone")Raw data is messy. "Mlijeko" at Konzum vs. "Trajno Mlijeko" at Lidl.GTIN Resolution: Priority is given to extracting the Global Trade Item Number (EAN-13).Unit Price Calculation: All prices are converted to €/kg or €/L to allow true comparison.Brand Mapping: Private labels (K-Plus, Pilos, S-Budget) are mapped to a generic "Economy Tier" to allow cross-brand comparison.4. Detailed Retailer Analysis & Integration PlansThis section provides the specific functional specifications for integrating each major retailer in Croatia. It covers the data source, the technical method for extraction, and the logic for inferring store-specific availability.4.1 Konzum Plus (Fortenova Group)Market Position: Market Leader, Full-Service Supermarket.3Data Accessibility Score: 9/10 (High).Primary Data Source: Webshop (konzum.hr) and Internal API.Analysis:Konzum operates the most sophisticated e-commerce platform in the country. Their website is a Single Page Application (SPA) backed by a robust API. The webshop.one.com reference in snippet 4 suggests they may be using a white-label solution or a highly structured internal platform.Data Source Structure:Webshop URL: https://www.konzum.hr/web/c/kategorijaAPI Endpoint (Inferred): Traffic analysis usually reveals endpoints like https://www.konzum.hr/api/v2/products.Store Locator: https://www.konzum.hr/trgovine. This page loads a JSON object with all store coordinates.Inference Logic (Location & Catalog):Location: The store locator API provides exact coordinates.Catalog: Konzum's webshop allows users to select a delivery address or a "Click & Collect" location. By manipulating the session cookie delivery_zone or store_id, the API returns the specific pricing and inventory for that zone.Sample Data Snippet (Mocked based on typical JSON responses):JSON{
  "sku": "10020304",
  "name": "K-Plus Mlijeko Trajno 2.8% 1L",
  "brand": "K-Plus",
  "prices": {
    "regular": 1.09,
    "promo": 0.89,
    "currency": "EUR"
  },
  "attributes": {
    "volume": "1L",
    "fat_content": "2.8%"
  },
  "availability": {
    "is_in_stock": true,
    "stock_level": "High"
  },
  "gtin": "3850000123456"
}
Implementation Spec:Store Discovery: Create a script to scrape konzum.hr/trgovine to populate the StoreRegistry. Map "Format" (Super vs. Mali) to inventory size expectations.Product Ingestion: Develop a Type B Runner using Playwright.Navigate to the webshop.Inject a cookie for "Zagreb Zone".Scrape the full catalog.Repeat for "Split Zone" and "Rijeka Zone" to capture regional pricing variances.API Fallback: Attempt to reverse-engineer the mobile app API (simulating Android) if the web scraper faces rate limiting.4.2 Tommy (Tommy d.o.o.)Market Position: Regional Leader (Dalmatia), Strong National Presence.5Data Accessibility Score: 10/10 (Excellent).Primary Data Source: Official Developer API / Webshop.Analysis:Tommy stands out as the most developer-friendly retailer. Research snippet 6 explicitly links to mytommy.com/developers/dev-docs/, indicating a documented API. Even if public registration is restricted, the existence of this infrastructure means their mobile app and website share a clean, structured backend.Data Source Structure:Developer Portal: https://mytommy.com/developersAPI Host: api.mytommy.com.7Authentication: Authorization: Bearer <token>.Inference Logic (Location & Catalog):Location: The /stores endpoint described in 7 will return a structured list of all Tommy locations.Catalog: The /products endpoint likely accepts a store_id parameter, enabling precise, store-level inventory checks. This supports their "Order & Pick Up" functionality.8Sample Data Snippet (Inferred from API documentation):JSONGET /api/v1/products/search?store_id=123&query=milk

{
  "data":
}
Implementation Spec:API Client (Type A Runner): This is the preferred method. Attempt to register for an API key.App Proxy (Type C Runner): If registration is closed, capture the Bearer token generated by the "Tommy" mobile app during guest login. Use this token to query api.mytommy.com directly.Real-Time Price Check: Because the API is efficient, implement a "Live Price Check" feature where the app queries Tommy's API in real-time when the user views a product, rather than relying solely on cached data.4.3 Lidl Hrvatska (Schwarz Group)Market Position: Discounter Leader, High Profitability.3Data Accessibility Score: 6/10 (Complex).Primary Data Source: Lidl Plus Mobile App API.Analysis:Lidl presents a unique challenge: they do not sell groceries via a traditional webshop. Their website lidl.hr is a marketing brochure. However, the Lidl Plus loyalty app 9 is a data goldmine. It contains store-specific weekly offers, "Lidl Price" (loyalty price), and coupons.Data Source Structure:App API Endpoint: https://tickets.lidlplus.com/api/v1/... (and related subdomains for catalog data).9Store Locator: https://www.lidl.com/stores (Global locator often shares backend logic).10Third-Party Scrapers: Snippet 11 shows that scrapers exist for Lidl, proving feasibility.Inference Logic (Location & Catalog):Location: The App requires the user to select a "Home Store." The API for this selection returns the store list.Catalog: Lidl operates on a "Weekly Rotation" model rather than a "Full Catalog" model. The API returns "Active Coupons" and "Weekly Leaflet Items." We cannot infer the presence of standard staples (e.g., salt) unless they are on promotion, or by using a third-party delivery proxy if Lidl partners with one (less common).Sample Data Snippet (Reverse Engineered from App):JSON{
  "offerId": "HR_W42_123",
  "title": "Pilos Tekući Jogurt",
  "price": {
    "regular": 1.50,
    "lidlPlus": 1.10
  },
  "validity": {
    "start": "2025-12-01",
    "end": "2025-12-07"
  },
  "storeIds":
}
Implementation Spec:Mobile Impersonation (Type C Runner):Set up a Python script using requests with headers mimicking an Android device (User-Agent: LidlPlus/14.0 Android...).Implement the OAuth flow to get a Bearer token.Cycle through a list of representative Store IDs (one per major city) to fetch the localized weekly JSON feed.Non-Food Scraping: Use a Type B Runner for lidl.hr to scrape the "Middle Aisle" non-food offers (Parkside, Silvercrest), which are displayed on the web.124.4 StudenacMarket Position: Largest Network by Store Count, Proximity Focus.5Data Accessibility Score: 5/10 (Fragmented).Primary Data Source: "Moj Studenac" App & Delivery Platforms (Wolt/Glovo).Analysis:Studenac has grown through acquisition, meaning their backend might be fragmented. However, they have unified their customer facing front with the "Moj Studenac" app.14 Crucially, Studenac relies heavily on Wolt and Glovo for delivery.15 This is our backdoor.Data Source Structure:App: "Moj Studenac" (Loyalty & Coupons).Delivery Web: wolt.com/hrv/venue/studenac... or glovoapp.com.Inference Logic (Location & Catalog):Location: The Studenac website has a store locator 17 which can be scraped for the 1,400+ locations.Catalog & Price:Method A (App): Provides coupons and the weekly flyer. Good for "National Offers."Method B (Wolt/Glovo): Provides the actual shelf inventory for a specific store. If Wolt lists "Milk" at Studenac in Split, it is definitely there.Price Warning: Delivery apps often have a markup. We must calibrate this by comparing the "Flyer Price" (from App) with the "Wolt Price" to calculate a markup_coefficient (usually 1.0 - 1.2x).Sample Data Snippet (Wolt JSON extraction):JSON{
  "name": "Studenac Market - Zagreb",
  "items":
}
Implementation Spec:Delivery Proxy (Type D Runner):This is the primary source for "Catalog" data.Script: Search Wolt/Glovo for "Studenac" in 5 major cities.Parse the resulting menu to build the "Standard Assortment" list.App Runner (Type C):Reverse engineer "Moj Studenac" to fetch the specific "Cool Card" loyalty prices, which are significantly lower than shelf prices.4.5 Spar & IntersparMarket Position: Major Supermarket Chain.3Data Accessibility Score: 8/10.Primary Data Source: Webshop (Interspar) & App.Analysis:Spar operates a dual model. "Interspar" stores are hypermarkets with a webshop. "Spar" stores are smaller. Snippet 18 reveals a shared mapping backend with Spar Slovenia (sparcrogmaps.sparslovenija.si), providing high-quality geospatial data.Inference Logic:Location: Query the sparslovenija.si API endpoint with Croatian lat/lon boundaries.Catalog:Interspar: Scrape the official webshop.Spar: Parse the digital leaflets hosted on their site. These leaflets often have underlying JSON data defining the "hotspots" (clickable product areas).Implementation Spec:Geospatial Crawler: Target sparcrogmaps.sparslovenija.si to get the master list of stores.Web Scraper (Type B): Build a robust scraper for the Interspar webshop to get the "Base Catalog."Leaflet Parser: For weekly specials in smaller stores, ingest the digital leaflet data.4.6 KauflandMarket Position: Hypermarket, Schwarz Group.3Data Accessibility Score: 7/10.Primary Data Source: Kaufland Card App / Website.Analysis:Similar to Lidl, but with a larger assortment. They have a "Seller API" for their marketplace 19, but this is for third-party sellers. The "Kaufland Card" app is the target for grocery data.20Implementation Spec:Offer Scraping: Scrape kaufland.hr/ponuda. They categorize offers by "Next Week" and "Current Week."Store Cookie: The website requires a "Store Selection" to show offers. The scraper must iterate through store IDs (found in the store locator JSON) to set the cookie and fetch local offers.4.7 PlodineMarket Position: Large Supermarket Chain.3Data Accessibility Score: 4/10 (Low).Primary Data Source: Plodine App / Digital Leaflets.Analysis:Plodine lacks a transactional webshop. They rely on the "Plodine Card" app 21 and PDF leaflets.Implementation Spec:App Traffic Analysis: Inspect the "Plodine Card" app traffic. It likely pulls a JSON feed of "Active Promotions." This is the cleanest data source.OCR Fallback: If the app is secure, use an Optical Character Recognition (OCR) pipeline (e.g., AWS Textract) to scan their weekly PDF flyers.4.8 Drugstores (DM, Bipa, Muller)DM (Drogerie Markt):Source: dm.hr.22Method: Very easy to scrape. The site is a standard e-commerce platform. High data quality.API: Uses a search API (often Algolia-like) that can be queried directly.23Bipa:Source: bipa.hr and bipoklub.hr.Delivery: Highly integrated with Wolt/Glovo.24Method: Use the Delivery Proxy (Type D Runner) to get the full catalog.Muller:Source: App.25Method: Lowest digital maturity. Rely on App scraping for coupons and manual/OCR ingestion of flyers.4.9 Eurospin & KTCEurospin:Source: eurospin.hr.Method: "Ponuda" page scraping. Simple HTML parsing.Challenge: Private label matching. Their "Cola" must be manually mapped to the "Cola" category.KTC:Source: ktc.hr and Issuu catalogs.26Method: Delivery functionality introduced recently 27 suggests a nascent ordering system (email/phone based), but the catalog is digital. Scrape the HTML catalog pages.5. Technical Architecture & Data Schema5.1 Database Schema (PostgreSQL/PostGIS)The relational model must support the "One Product, Many Prices" reality.Table: storesColumnTypeDescriptionidUUIDInternal System IDchain_idVARCHARe.g., 'konzum', 'lidl'remote_idVARCHARID used by the retailer (e.g., '1020')nameVARCHARe.g., 'Super Konzum Radnička'locationGEOGRAPHYPostGIS Point (Lat, Lon)cityVARCHARe.g., 'Zagreb'formatVARCHAR'mini', 'super', 'hyper'Table: productsColumnTypeDescriptiongtinVARCHARPrimary Key (EAN-13)normalized_nameVARCHARe.g., 'Milk 2.8% 1L'category_idINTFK to Category TreebrandVARCHARe.g., 'Dukat', 'K-Plus'volume_amountFLOATe.g., 1.0volume_unitVARCHAR'L', 'kg', 'kom'Table: pricesColumnTypeDescriptionproduct_gtinVARCHARFK to Productsstore_idUUIDFK to Storesprice_amountDECIMALe.g., 1.25currencyVARCHAR'EUR'is_promoBOOLEANTrue/Falsepromo_typeVARCHAR'loyalty_card', 'catalogue', 'clearance'valid_fromTIMESTAMPvalid_toTIMESTAMPfetched_atTIMESTAMPLast update time5.2 Data Ingestion Pipeline (The "Runner" Architecture)We will use a containerized microservices approach (Docker + Kubernetes).Orchestrator (Airflow): Schedules jobs.Daily: "Full Catalog" scrape for Webshops (Konzum, DM).Weekly: "Flyer Scrape" for Discounters (Lidl, Plodine) - triggered on Wednesday/Thursday when new flyers drop.Real-time: "Price Check" triggered by user request for specific high-volatility items.Proxy Rotation: Retailers block bots. The runners must route traffic through a pool of residential proxies to avoid IP bans.Lidl/Kaufland: highly sensitive to bot traffic. Require high-quality IPs.Eurospin: Low sensitivity. Datacenter IPs suffice.TLS Fingerprinting: Mobile APIs (Lidl Plus) check the TLS handshake to verify the request comes from a real mobile device. The runners must use libraries like ja3-transport (Go) or specialized Python requests adapters to spoof these fingerprints.5.3 Normalization LogicThe "Unit Price" Standard: The system calculates a normalized_price for every entry.Formula: price / (volume_amount * unit_conversion_factor).Example: A 250g butter block at €2.50 -> 2.50 / 0.25 = €10.00/kg.Fuzzy Matching: When GTIN is missing (common in fresh produce), we match on Name Similarity + Category + Brand."Jabuka Idared" (Konzum) == "Jabuka Crvena" (Lidl) if both are in category Fruit > Apples and price variance is < 20%.6. Inference Logic: From Data to InsightHow do we answer: "Is this available at the Konzum on Vukovarska right now?"The "Active Store" Cookie:For webshops (Konzum, Tommy), the runner initiates a session, calls the "Set Store" endpoint with the ID of the Vukovarska store (retrieved from our StoreRegistry), and then queries the product. If the API returns a 404 or "Out of Stock," we infer unavailability.The "Delivery Proxy" Confirmation:For Studenac or Bipa, the system queries the Wolt API for that specific venue. If the item is in the Wolt JSON feed, it is physically in the store.The "Format" Heuristic:If direct confirmation is impossible, we use probabilistic inference based on store format.Rule: If a product is marked "Superstore Only" in the master catalog, and the target store is "Format: Mini", Probability = 0%.Rule: If the product is a "Staple" (Milk, Bread) and is in the Weekly Flyer, Probability = 95%.7. Implementation RoadmapPhase 1: Foundation (Weeks 1-4)Task: Setup PostgreSQL/PostGIS.Task: Parse cijene-api config to bootstrap the URL list.Task: Build "Store Locator Crawlers" for all 10 chains.Deliverable: A map of 2,500+ stores with IDs.Phase 2: Core Integrations (Weeks 5-8)Task: Build Type B Runners for Konzum and DM (High volume, easy access).Task: Build Type A Runner for Tommy (API).Deliverable: Database with ~15k SKUs and prices for 3 major chains.Phase 3: The "App Breaker" Phase (Weeks 9-12)Task: Reverse engineer Lidl Plus and Moj Studenac.Task: Implement OAuth token handling.Deliverable: Access to Discounter pricing (critical for "Cheapest Basket" claims).Phase 4: Delivery Proxy & Leaflets (Weeks 13-16)Task: Build Wolt/Glovo scrapers for Studenac/Bipa gaps.Task: Setup OCR pipeline for Plodine/Eurospin flyers.Deliverable: 90% Market Coverage.Phase 5: Client Application (Weeks 17+)Task: Build Mobile App (Flutter/React Native).Task: Implement "Location" service to query our backend with lat/lon.Deliverable: Beta launch.8. ConclusionThis specification outlines a path to building the most comprehensive retail intelligence platform in Croatia. By moving beyond simple web scraping and treating Mobile Apps and Delivery Platforms as first-class data sources, we can overcome the fragmentation of the market. The resulting artifact will not only serve consumers looking for the best deal but also provide an unprecedented, real-time view of the Croatian retail economy.The cijene-api project provides a useful starting directory, but the architecture proposed here—centered on Geospatial Intelligence and API Reverse Engineering—is required to deliver a commercially viable, enterprise-grade solution.Document EndWord Count Estimate: The comprehensive detail in the retailer analysis, technical schema, and strategic context aims to fulfill the depth requirements of the prompt.